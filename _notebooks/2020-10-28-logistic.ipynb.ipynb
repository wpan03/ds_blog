{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This post is going to introduce logistic regression with an emphasis on explaining the coefficients in the output of Python's statsmodels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is used to solve the classification problem. Classification problem means the dependent variable is categorical. For example, we can build a machine learning model to predict whether a student will be admitted to college based on metrics like his or her GPA, standardized test scores. If we formulate a classification problem in mathematical form, we have:\n",
    "\n",
    "\\begin{equation}\n",
    "y = \\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{2},\n",
    "\\end{equation}\n",
    "where y is a categorical variable, like whether you are admited or not.\n",
    "\n",
    "One way to approach this problem is by using linear regression. However, we would like our algorithm will output a number between 0 and 1, which can indicate the probability of an observation belonging to a certain category. Linear regression does not satisfy this requirement as it might output values smaller than 0 or larger than 1.\n",
    "\n",
    "One solution is to solve this problem is to transform the value of $\\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{2}$ to the range of [0,1]. We can do this with the logistic function:\n",
    "$$f(x)=\\frac{e^{x}}{1+e^{x}}$$.\n",
    "\n",
    "To show that logistic regression will make a number between 0 and 1. Let's make a plot of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(x):\n",
    "    return np.exp(x)/(1+np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-100, 100, 0.1)\n",
    "y = logit(x)\n",
    "plt.plot(x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the logit function has a S shape and is bounded by 0 and 1. When x is approaching positive infinity, the logit of x approaches 1. When x is approaching negative infinity, the logit of x approaches 0.\n",
    "\n",
    "Thus, we can transform the value of $\\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{2}$ to:\n",
    "\n",
    "$$\n",
    "p(X)=\\frac{e^{\\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{2}}}{1+e^{\\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{2}}}\n",
    "$$\n",
    "\n",
    "Now the output of our regression will fall between zero and one. Since we the logistic function to achieve this, the regression is called logistic regression. Before jumping into the details of behind it, let's first we how to run it in python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Python Implementation of Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this post, we are going to use a college admission dataset from [UCLA's Institute for Digital Research & Education](https://stats.idre.ucla.edu/). We want to use a student's GRE score, GPA, and rank to predict whether he will be admitted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://stats.idre.ucla.edu/stat/data/binary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the statsmodel to run the logistic regression. We choose statsmodel because its interface and summary of the result are more similar to other statistical software, like R and Stata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = smf.ols(formula='admit ~ gre + gpa + rank', data=df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>admit</td>      <th>  R-squared:         </th> <td>   0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   14.02</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 20 Nov 2020</td> <th>  Prob (F-statistic):</th> <td>1.05e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:48:20</td>     <th>  Log-Likelihood:    </th> <td> -241.53</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   491.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   396</td>      <th>  BIC:               </th> <td>   507.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.1824</td> <td>    0.217</td> <td>   -0.841</td> <td> 0.401</td> <td>   -0.609</td> <td>    0.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gre</th>       <td>    0.0004</td> <td>    0.000</td> <td>    2.106</td> <td> 0.036</td> <td> 2.94e-05</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gpa</th>       <td>    0.1510</td> <td>    0.063</td> <td>    2.383</td> <td> 0.018</td> <td>    0.026</td> <td>    0.276</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank</th>      <td>   -0.1095</td> <td>    0.024</td> <td>   -4.608</td> <td> 0.000</td> <td>   -0.156</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>190.649</td> <th>  Durbin-Watson:     </th> <td>   1.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>  51.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.667</td>  <th>  Prob(JB):          </th> <td>6.81e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.858</td>  <th>  Cond. No.          </th> <td>6.00e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large,  6e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  admit   R-squared:                       0.096\n",
       "Model:                            OLS   Adj. R-squared:                  0.089\n",
       "Method:                 Least Squares   F-statistic:                     14.02\n",
       "Date:                Fri, 20 Nov 2020   Prob (F-statistic):           1.05e-08\n",
       "Time:                        14:48:20   Log-Likelihood:                -241.53\n",
       "No. Observations:                 400   AIC:                             491.1\n",
       "Df Residuals:                     396   BIC:                             507.0\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.1824      0.217     -0.841      0.401      -0.609       0.244\n",
       "gre            0.0004      0.000      2.106      0.036    2.94e-05       0.001\n",
       "gpa            0.1510      0.063      2.383      0.018       0.026       0.276\n",
       "rank          -0.1095      0.024     -4.608      0.000      -0.156      -0.063\n",
       "==============================================================================\n",
       "Omnibus:                      190.649   Durbin-Watson:                   1.950\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               51.425\n",
       "Skew:                           0.667   Prob(JB):                     6.81e-12\n",
       "Kurtosis:                       1.858   Cond. No.                     6.00e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large,  6e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Interpretation of the Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Probability, odd, log-odd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $k = \\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{2}$. Then we have: $p(X)=\\frac{e^{k}}{1+e^{k}}$.\n",
    "\n",
    "Then, $p(x) + p(x)e^k = e^k$. Then $p(x) = e^k - p(x)e^k = e^k(1-p(x))$. Thus, $e^{k} = \\frac{p(x)}{1-p(x)}$.\n",
    "The quantity $\\frac{p(x)}{1-p(x)}$ is called the *odds*.\n",
    "\n",
    "Taking log from both side the odds equation, we have $k= log(\\frac{p(x)}{1-p(x)})$. This quantity $log(\\frac{p(x)}{1-p(x)})$ the *log-odds*.\n",
    "\n",
    "Bringing back the value of k, we have: $log(\\frac{p(x)}{1-p(x)}) =  \\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{2}$. \n",
    "\n",
    "What we are actually evaluating when running the python code in the section is the equation above. Thus, the prediction we made is not the probability, but the log-odds.\n",
    "\n",
    "To evaluate the probability, we can put the log-odds we predict back to the formula $p(X)=\\frac{e^{k}}{1+e^{k}}$, as k is the log-odd we predict.\n",
    "\n",
    "In code, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_from_log_odd(log_odds):\n",
    "    prob = np.exp(log_odds)/1+np.exp(log_odds)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Coefficient Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Estimation Method"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
